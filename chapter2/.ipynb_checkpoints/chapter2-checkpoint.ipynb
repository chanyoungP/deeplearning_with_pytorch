{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8baa6e",
   "metadata": {},
   "source": [
    "## 딥러닝 파이토치 교과서 \n",
    "### chapter 2  \n",
    "#### 파이토치 기초 문법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df3362",
   "metadata": {},
   "source": [
    "#### 텐서 생성 및 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336fd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor([[1,2],[3,4]])) # 2차원 형태의 텐서 생성 \n",
    "print(torch.tensor([[1,2],[3,4]], device = \"cuda:0\")) # gpu에 텐서 생성 \n",
    "print(torch.tensor([[1,2],[3,4]],dtype = torch.float64)) # dtype을 이용하여 텐서 생성\n",
    "\n",
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp.numpy()) # tensor를 넘파이 배열로 변환 \n",
    "\n",
    "temp = torch.tensor([[1,2],[3,4]],device = \"cuda:0\")\n",
    "print(temp.to(\"cpu\").numpy()) #gpu상의 텐서를 cpu의 텐서로 변환한 후 넘파이 배열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c86079",
   "metadata": {},
   "source": [
    "#### 텐서의 인덱스 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918e92be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "--------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1,2,3,4,5,6,7]) #1차원 벡터 생성\n",
    "print(temp[0],temp[1],temp[-1]) # 인덱스로 접근 \n",
    "print(\"--------------------\") \n",
    "print(temp[2:5],temp[4:-1]) #슬라이스로 접근 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d78c23",
   "metadata": {},
   "source": [
    "#### 텐서 연산 및 차원 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f9353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1,2,3]) \n",
    "w = torch.tensor([3,4,6]) \n",
    "\n",
    "print(w - v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0367b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "----------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "----------------\n",
      "tensor([1, 2, 3, 4])\n",
      "----------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "----------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "#차원 조작\n",
    "temp = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "print(temp.shape)\n",
    "print(\"----------------\")\n",
    "print(temp.view(4,1)) # 4x1 로 변환 \n",
    "print(\"----------------\")\n",
    "print(temp.view(-1)) # 1차원 벡터로 변형\n",
    "print(\"----------------\")\n",
    "print(temp.view(1,-1)) # -1은 (1,?)과 같은 의미로 다른 차원으로부터 해당 값을 유추하겠다는 것 여기서는 (1,4)로 유추\n",
    "print(\"----------------\")\n",
    "print(temp.view(-1,1)) # 마찬가지로 (?,1)과 같은 의미로 -1에 해당하는 차원은 유추하여 (4,1)로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512ffae",
   "metadata": {},
   "source": [
    "### 2.2.2 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581b3a5",
   "metadata": {},
   "source": [
    "#### 단순하게 파일을 불러와서 사용하는 경우 _ 실제 사용하는 데이터가 없기 때문에 실행 시 오류  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "data = pd.read_csv('data_path') #예제라 실제 데이터는 존재하지 않음.\n",
    "\n",
    "#CSV파일의 x칼럼의 값을 넘파이 배열로 받아 Tensor로 바꾸어 준다. \n",
    "x = torch.from_numy(data['x'].values).unsqueeze(dim=1).float() \n",
    "y = torch.from_numy(data['y'].values).unsqueeze(dim=1).float() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d78cb",
   "metadata": {},
   "source": [
    "#### 커스텀 데이터셋을 만들어서 사용하는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535a7bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1953bf8f9e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,csv_file): # csv_file 파라미터를 통해 데이터셋을 불러온다. \n",
    "        self.label = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self): #전체 데이터셋의 size를 반환합니다. \n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self,idx): #전체 x와 y데이터 중에 해당 idx번째의 데이터를 가져옵니다. \n",
    "        sample = torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "        label = torch.tensor(self.label.iloc[idx,3]).int()\n",
    "        \n",
    "        return sample, label\n",
    "    \n",
    "tensor_dataset = CustomDataset('C:/Users/CoIn241/Desktop/chan/torchbook_data/chap02/data/car_evaluation.csv')\n",
    "dataset = DataLoader(tensor_dataset,batch_size=4,shuffle = True) \n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4392a0d",
   "metadata": {},
   "source": [
    "#### 파이토치에서 제공하는 데이터셋을 사용하는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b1dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 다운 예제 \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(1.0)) #평균이 0.5 표준편차가 1.0이 되도록 데이터 분포를 조정\n",
    "])\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import requests \n",
    "\n",
    "download_root = 'donwload_path' #다운받을 경로 지정 \n",
    "\n",
    "train_dataset = MNIST(download_root,transform=mnist_transform,train=True,downlaod=True)\n",
    "valid_dataset = MNIST(download_root,transform=mnist_transform,train=False,downlaod=True)\n",
    "test_dataset = MNIST(download_root,transform=mnist_transform,train=False,downlaod=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e218ded",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eadf276",
   "metadata": {},
   "source": [
    "#### 단순 신경망을 정의하는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421c3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model = nn.Linear(in_features =1, out_features=1, bias = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969cf8d4",
   "metadata": {},
   "source": [
    "#### nn.Module()을 상속하여 정의하는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d239f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,inputs):\n",
    "        super(MLP,self).__init__()\n",
    "        self.layer = Linear(inputs,1)  # 계층 정의 \n",
    "        self.activation = Sigmoid() # 활성화 함수 정의\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff339a",
   "metadata": {},
   "source": [
    "#### Sequential 신경망을 정의하는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d10bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing children\n",
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")]\n",
      "printing Modules\n",
      "[MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=30,kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=30*5*5,out_features=10,bias=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MLP() # 모델에 대한 객체 생성\n",
    "\n",
    "print(\"Printing children\")\n",
    "print(list(model.children())) #같은 수준의 하위 노드를 반환  :::: Sequential 밑에 layer 인데, layer 수준만 \n",
    "print(\"printing Modules\")\n",
    "print(list(model.modules())) # 모델 네트워크의 모든 노드를 반환 :::: Sequential 밑에 layer인데, 모두 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a76b5c",
   "metadata": {},
   "source": [
    "#### 함수로 신경망을 정의하는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffbde6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(in_features=1,hidden_features=20,out_featrues=1):\n",
    "    hidden = nn.Linear() #인자 지정해줘야 함 오류 발생\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear()\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6a103",
   "metadata": {},
   "source": [
    "### 2.2.4 모델의 파라미터 정의 \n",
    "- 손실함수\n",
    "- 옵티마이저\n",
    "- 스케줄러 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f4dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas_env",
   "language": "python",
   "name": "nas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
